<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Probador Virtual de Gorras AR Mejorado</title>
    <style>
        body { margin: 0; overflow: hidden; font-family: Arial, sans-serif; }
        #loading-screen {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.8);
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 1000;
            color: white;
            font-size: 24px;
        }
        #error-message {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(255, 0, 0, 0.8);
            color: white;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            display: none;
            z-index: 1001;
        }
        video {
            display: none;
        }
    </style>
</head>
<body>
    <div id="loading-screen">Cargando experiencia AR...</div>
    <div id="error-message"></div>

    <!-- Importación de bibliotecas de MediaPipe Face Mesh y Camera Utils -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

    <!-- Importación de módulos de Three.js y GLTFLoader utilizando rutas relativas -->
    <script type="module">
        import * as THREE from 'https://unpkg.com/three@0.152.2/build/three.module.js';
        import { GLTFLoader } from 'https://unpkg.com/three@0.152.2/examples/jsm/loaders/GLTFLoader.js';

        let scene, camera, renderer, hatModel, video, videoTexture, faceMesh, cameraFeed;

        // Función de inicialización principal
        async function init() {
            try {
                // Configuración de Three.js
                scene = new THREE.Scene();

                // Configuración de la cámara
                camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 1000);
                camera.position.z = 0; // Posición en el centro

                // Configuración del renderer
                renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
                renderer.setSize(window.innerWidth, window.innerHeight);
                renderer.setPixelRatio(window.devicePixelRatio);
                document.body.appendChild(renderer.domElement);

                // Añadir video como fondo
                video = document.createElement('video');
                video.style.display = 'none';
                document.body.appendChild(video);

                // Solicitar acceso a la cámara
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
                video.srcObject = stream;
                await video.play();

                // Crear textura de video
                videoTexture = new THREE.VideoTexture(video);
                videoTexture.minFilter = THREE.LinearFilter;
                videoTexture.magFilter = THREE.LinearFilter;
                videoTexture.format = THREE.RGBFormat;

                // Crear plano para mostrar el video
                const videoGeometry = new THREE.PlaneGeometry(2, 2);
                const videoMaterial = new THREE.MeshBasicMaterial({ map: videoTexture });
                const videoMesh = new THREE.Mesh(videoGeometry, videoMaterial);
                videoMesh.position.z = -1; // Detrás de otros objetos
                scene.add(videoMesh);

                // Iluminación
                const ambientLight = new THREE.AmbientLight(0xffffff, 1);
                scene.add(ambientLight);

                // Cargar modelo de gorra
                await loadHatModel('https://nicolascumbej.github.io/arexperience/baseball_cap.glb');

                // Configurar detección facial con MediaPipe Face Mesh
                setupFaceMesh();

                // Iniciar animación
                animate();

                // Ocultar pantalla de carga
                document.getElementById('loading-screen').style.display = 'none';
            } catch (error) {
                console.error('Error durante la inicialización:', error);
                showError('Hubo un error al iniciar la experiencia AR. Por favor, recarga la página y verifica los permisos de la cámara.');
            }
        }

        // Función para cargar el modelo de la gorra
        function loadHatModel(url) {
            return new Promise((resolve, reject) => {
                const loader = new GLTFLoader();
                loader.load(
                    url,
                    (gltf) => {
                        hatModel = gltf.scene;
                        hatModel.scale.set(0.15, 0.15, 0.15); // Ajusta la escala según sea necesario
                        scene.add(hatModel);
                        resolve();
                    },
                    undefined,
                    (error) => {
                        console.error('Error cargando el modelo:', error);
                        reject(error);
                    }
                );
            });
        }

        // Función para configurar MediaPipe Face Mesh
        function setupFaceMesh() {
            faceMesh = new FaceMesh.FaceMesh({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
                }
            });

            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            faceMesh.onResults(onResults);

            cameraFeed = new CameraUtils.Camera(video, {
                onFrame: async () => {
                    await faceMesh.send({ image: video });
                },
                width: 640,
                height: 480
            });
            cameraFeed.start();
        }

        // Función de resultados de MediaPipe
        function onResults(results) {
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const landmarks = results.multiFaceLandmarks[0];

                // Obtener puntos clave para posición y rotación
                const foreheadLandmark = landmarks[10]; // Punto en la frente
                const chinLandmark = landmarks[152]; // Punto en el mentón
                const leftEarLandmark = landmarks[234];
                const rightEarLandmark = landmarks[454];

                // Calcular posición promedio de la cabeza
                const headCenter = {
                    x: (foreheadLandmark.x + chinLandmark.x) / 2,
                    y: (foreheadLandmark.y + chinLandmark.y) / 2,
                    z: (foreheadLandmark.z + chinLandmark.z) / 2
                };

                // Convertir coordenadas normalizadas a coordenadas de Three.js
                const x = (headCenter.x - 0.5) * 2;
                const y = -(headCenter.y - 0.5) * 2;

                // Actualizar posición de la gorra
                hatModel.position.set(x, y + 0.2, 0); // Ajusta según sea necesario

                // Calcular rotación en el eje Y (yaw)
                const dx = rightEarLandmark.x - leftEarLandmark.x;
                const dy = rightEarLandmark.z - leftEarLandmark.z;
                const yaw = Math.atan2(dy, dx);

                hatModel.rotation.set(0, yaw, 0);
            }
        }

        // Función de animación
        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }

        // Función para mostrar errores al usuario
        function showError(message) {
            const errorElement = document.getElementById('error-message');
            errorElement.textContent = message;
            errorElement.style.display = 'block';
            document.getElementById('loading-screen').style.display = 'none';
        }

        // Listener para redimensionar la ventana
        window.addEventListener('resize', () => {
            if (camera && renderer) {
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(window.innerWidth, window.innerHeight);
            }
        });

        // Iniciar la aplicación
        init();
    </script>
</body>
</html>
