<!DOCTYPE html>
<html>
<head>
  <title>AR.js with Three.js and MediaPipe</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; font-family: Arial, sans-serif; }
    #label { position: absolute; top: 10px; left: 10px; color: white; background: rgba(0, 0, 0, 0.5); padding: 5px 10px; border-radius: 4px; font-size: 16px; display: none; }
    canvas { position: absolute; top: 0; left: 0; }
  </style>
</head>
<body>
  <div id="label">Cara reconocida</div>
  <video id="input_video" style="display:none;"></video>
  <canvas id="output_canvas" width="1280" height="720"></canvas>
  <script>
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');

    // Inicializar Three.js
    let scene, camera, renderer, hat;

    try {
      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
      renderer = new THREE.WebGLRenderer({ canvas: canvasElement, alpha: true });
      renderer.setSize(window.innerWidth, window.innerHeight);

      const light = new THREE.AmbientLight(0xffffff, 1);
      scene.add(light);

      // Cargar modelo 3D
      const loader = new THREE.OBJLoader();

      loader.load(
        'https://nicolascumbej.github.io/arexperience/tmp2h0xvw1a.obj',
        function (object) {
          hat = object;
          scene.add(hat);
        },
        function (xhr) {
          console.log((xhr.loaded / xhr.total * 100) + '% loaded');
        },
        function (error) {
          console.error('An error happened', error);
        }
      );

      camera.position.z = 5;

    } catch (error) {
      console.error('Error creating WebGL context:', error);
      alert('Error creating WebGL context. Please check your browser compatibility.');
    }

    // Inicializar MediaPipe
    const faceMesh = new FaceMesh({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(onResults);

    const cameraUtils = new Camera(videoElement, {
      onFrame: async () => {
        await faceMesh.send({ image: videoElement });
      },
      width: 1280,
      height: 720
    });
    cameraUtils.start();

    function onResults(results) {
      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        const noseTip = landmarks[1];
        const leftEar = landmarks[234];
        const rightEar = landmarks[454];

        if (hat) {
          const position = new THREE.Vector3(
            (noseTip.x * 2 - 1) * 1.5,
            -(noseTip.y * 2 - 1) * 1.5,
            -0.5
          );

          const scale = new THREE.Vector3(
            Math.abs(leftEar.x - rightEar.x) * 10,
            Math.abs(leftEar.y - rightEar.y) * 10,
            Math.abs(leftEar.x - rightEar.x) * 10
          );

          hat.position.copy(position);
          hat.scale.copy(scale);
        }
      }
    }

    function animate() {
      if (renderer && scene && camera) {
        requestAnimationFrame(animate);
        renderer.render(scene, camera);
      }
    }
    animate();
  </script>
</body>
</html>
