<!DOCTYPE html>
<html>
<head>
  <title>AR.js con Three.js y TensorFlow.js</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  <script src="https://cdn.rawgit.com/jeromeetienne/AR.js/1.6.0/aframe/build/aframe-ar.js"></script>
  <style>
    body { margin: 0; overflow: hidden; font-family: Arial, sans-serif; }
    #label, #modelInfo {
      position: absolute; 
      color: white; 
      background: rgba(0, 0, 0, 0.5); 
      padding: 5px 10px; 
      border-radius: 4px; 
      font-size: 16px; 
      display: none;
    }
    #label { top: 10px; left: 10px; }
    #modelInfo { bottom: 10px; left: 10px; }
    #canvas { position: absolute; top: 0; left: 0; z-index: 0; }
  </style>
</head>
<body>
  <div id="label">Cara reconocida</div>
  <div id="modelInfo">Información del modelo</div>
  <video id="input_video" width="1280" height="720" style="position: absolute; top: 0; left: 0; z-index: -1;"></video>
  <canvas id="canvas" width="1280" height="720"></canvas>
  <a-scene embedded arjs="trackingMethod: best; sourceType: webcam;">
    <a-assets>
      <a-asset-item id="hatModel" src="https://nicolascumbej.github.io/arexperience/tmp2h0xvw1a.obj"></a-asset-item>
    </a-assets>
    <a-entity id="hat" scale="0.3 0.3 0.3" position="0 0 0" rotation="0 0 0" visible="false">
      <a-obj-model src="#hatModel" material="color: #1565C0; metalness: 0.1; roughness: 0.9;"></a-obj-model>
    </a-entity>
    <a-entity camera></a-entity>
  </a-scene>
  <script>
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('canvas');
    const canvasCtx = canvasElement.getContext('2d');
    const labelElement = document.getElementById('label');
    const modelInfoElement = document.getElementById('modelInfo');

    let model;

    async function loadModel() {
      model = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);
      modelInfoElement.textContent = 'Modelo cargado correctamente';
      modelInfoElement.style.display = 'block';
    }

    async function detectFace() {
      const predictions = await model.estimateFaces({
        input: videoElement,
        returnTensors: false,
        flipHorizontal: false,
        predictIrises: false
      });

      if (predictions.length > 0) {
        const landmarks = predictions[0].scaledMesh;
        const boundingBox = calculateBoundingBox(landmarks);
        const centerX = (boundingBox.minX + boundingBox.maxX) / 2;
        const centerY = (boundingBox.minY + boundingBox.maxY) / 2;
        const headWidth = boundingBox.maxX - boundingBox.minX;
        const headHeight = boundingBox.maxY - boundingBox.minY;
        const depth = calculateDepth(landmarks);

        // Dibujar la malla facial en el canvas
        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        canvasCtx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
        canvasCtx.beginPath();
        canvasCtx.lineWidth = 0.5;
        canvasCtx.strokeStyle = 'blue';
        for (let i = 0; i < landmarks.length; i++) {
          const x = landmarks[i][0] * canvasElement.width;
          const y = landmarks[i][1] * canvasElement.height;
          if (i === 0) {
            canvasCtx.moveTo(x, y);
          } else {
            canvasCtx.lineTo(x, y);
          }
        }
        canvasCtx.closePath();
        canvasCtx.stroke();
        canvasCtx.restore();

        const scaleFactor = 1 / depth;

        const position = {
          x: kalmanFilters.x.filter((centerX - 0.5) * 2),
          y: kalmanFilters.y.filter((centerY - 0.5) * -2 - 0.2 * scaleFactor),
          z: kalmanFilters.z.filter((0.5 - depth) * 2)
        };

        const scale = {
          x: headWidth * 0.7 * scaleFactor,
          y: headHeight * 0.7 * scaleFactor,
          z: headWidth * 0.7 * scaleFactor
        };

        const leftEyeInner = landmarks[133];
        const rightEyeInner = landmarks[362];
        const noseTip = landmarks[1];
        const dx = rightEyeInner[0] - leftEyeInner[0];
        const dy = rightEyeInner[1] - leftEyeInner[1];
        const dz = noseTip[2] - landmarks[1][2];

        const angleX = Math.atan2(dy, dz) * (180 / Math.PI);
        const angleY = Math.atan2(dz, dx) * (180 / Math.PI);
        const angleZ = Math.atan2(dy, dx) * (180 / Math.PI);

        const rotation = {
          x: kalmanFilters.angleX.filter(angleX),
          y: kalmanFilters.angleY.filter(-angleY + 180),
          z: kalmanFilters.angleZ.filter(angleZ)
        };

        labelElement.innerHTML = `Anchura de la cabeza: ${headWidth.toFixed(2)}<br>Altura de la cabeza: ${headHeight.toFixed(2)}`;
        labelElement.style.display = 'block';

        const hat = document.querySelector('#hat');
        hat.setAttribute('position', `${position.x} ${position.y} ${position.z}`);
        hat.setAttribute('scale', `${scale.x} ${scale.y} ${scale.z}`);
        hat.setAttribute('rotation', `${rotation.x} ${rotation.y} ${rotation.z}`);
        hat.setAttribute('visible', true);
      } else {
        const hat = document.querySelector('#hat');
        hat.setAttribute('visible', false);
        labelElement.style.display = 'none';
      }

      requestAnimationFrame(detectFace);
    }

    function calculateBoundingBox(landmarks) {
      let minX = 1.0, minY = 1.0, maxX = 0.0, maxY = 0.0;
      landmarks.forEach(landmark => {
        minX = Math.min(minX, landmark[0]);
        minY = Math.min(minY, landmark[1]);
        maxX = Math.max(maxX, landmark[0]);
        maxY = Math.max(maxY, landmark[1]);
      });
      return { minX, minY, maxX, maxY };
    }

    function calculateDepth(landmarks) {
      const leftEye = landmarks[133];
      const rightEye = landmarks[362];
      const noseTip = landmarks[1];
      const jawMid = landmarks[152];

      const faceWidth = Math.sqrt(Math.pow(rightEye[0] - leftEye[0], 2) + Math.pow(rightEye[1] - leftEye[1], 2) + Math.pow(rightEye[2] - leftEye[2], 2));
      const faceHeight = Math.sqrt(Math.pow(noseTip[0] - jawMid[0], 2) + Math.pow(noseTip[1] - jawMid[1], 2) + Math.pow(noseTip[2] - jawMid[2], 2));
      const depth = Math.max(faceWidth, faceHeight);

      return depth;
    }

    class KalmanFilter {
      constructor({ R, Q, A, B, C }) {
        this.R = R;
        this.Q = Q;
        this.A = A;
        this.B = B;
        this.C = C;
        this.cov = NaN;
        this.x = NaN;
      }

      filter(z, u = 0) {
        if (isNaN(this.x)) {
          this.x = 1 / this.C * z;
          this.cov = 1 / this.C * this.Q * (1 / this.C);
        } else {
          const predX = this.A * this.x + this.B * u;
          const predCov = this.A * this.cov * this.A + this.R;
          const K = predCov * this.C * (1 / (this.C * predCov * this.C + this.Q));
          this.x = predX + K * (z - this.C * predX);
          this.cov = predCov - K * this.C * predCov;
        }
        return this.x;
      }
    }

    const kalmanFilters = {
      x: new KalmanFilter({ R: 0.005, Q: 4, A: 1, B: 0, C: 1 }),
      y: new KalmanFilter({ R: 0.005, Q: 4, A: 1, B: 0, C: 1 }),
      z: new KalmanFilter({ R: 0.005, Q: 4, A: 1, B: 0, C: 1 }),
      angleX: new KalmanFilter({ R: 0.005, Q: 4, A: 1, B: 0, C: 1 }),
      angleY: new KalmanFilter({ R: 0.005, Q: 4, A: 1, B: 0, C: 1 }),
      angleZ: new KalmanFilter({ R: 0.005, Q: 4, A: 1, B: 0, C: 1 })
    };

    loadModel().then(() => {
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
          videoElement.srcObject = stream;
          videoElement.play();
          detectFace();
        })
        .catch(error => {
          console.error('Error al acceder a la cámara:', error);
          alert('No se pudo acceder a la cámara. Verifica los permisos y asegúrate de que no esté siendo utilizada por otra aplicación.');
        });
    });
  </script>
</body>
</html>
