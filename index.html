<!DOCTYPE html>
<html>
<head>
  <title>AR.js with Three.js and MediaPipe</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; font-family: Arial, sans-serif; }
    #label { position: absolute; top: 10px; left: 10px; color: white; background: rgba(0, 0, 0, 0.5); padding: 5px 10px; border-radius: 4px; font-size: 16px; }
    #output_canvas { display: none; }
    #startButton { position: absolute; top: 10px; right: 10px; padding: 5px 10px; border-radius: 4px; font-size: 16px; cursor: pointer; }
  </style>
</head>
<body>
  <div id="label">Cara reconocida</div>
  <button id="startButton">Iniciar cámara</button>
  <video id="input_video" style="display:none;"></video>
  <canvas id="output_canvas" width="1280" height="720"></canvas>
  <a-scene embedded arjs="trackingMethod: best; sourceType: webcam;">
    <a-assets>
      <a-asset-item id="hatModel" src="https://nicolascumbej.github.io/arexperience/tmp2h0xvw1a.obj"></a-asset-item>
    </a-assets>
    <a-marker preset="hiro">
      <a-entity id="hat" obj-model="obj: #hatModel" scale="0.05 0.05 0.05" position="0 0 0" rotation="0 0 0"></a-entity>
    </a-marker>
    <a-entity camera></a-entity>
  </a-scene>
  <script>
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');
    const labelElement = document.getElementById('label');
    const startButton = document.getElementById('startButton');

    let cameraUtils = null;
    let isCameraRunning = false;

    // Inicializar MediaPipe
    const faceMesh = new FaceMesh({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.8,
      minTrackingConfidence: 0.8
    });

    faceMesh.onResults(onResults);

    startButton.addEventListener('click', toggleCamera);

    function toggleCamera() {
      if (isCameraRunning) {
        stopCamera();
      } else {
        startCamera();
      }
    }

    function startCamera() {
      if (!cameraUtils) {
        cameraUtils = new Camera(videoElement, {
          onFrame: async () => {
            await faceMesh.send({ image: videoElement });
          },
          width: 1280,
          height: 720
        });
      }
      cameraUtils.start();
      isCameraRunning = true;
      startButton.textContent = 'Detener cámara';
    }

    function stopCamera() {
      if (cameraUtils) {
        cameraUtils.stop();
      }
      isCameraRunning = false;
      startButton.textContent = 'Iniciar cámara';
    }

    function onResults(results) {
      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        const noseTip = landmarks[1];
        const leftEar = landmarks[234];
        const rightEar = landmarks[454];

        const hat = document.querySelector('#hat');

        if (hat) {
          const position = {
            x: (noseTip.x * 2 - 1) * 1.5,
            y: -(noseTip.y * 2 - 1) * 1.5,
            z: -0.5
          };

          const scale = {
            x: Math.abs(leftEar.x - rightEar.x) * 10,
            y: Math.abs(leftEar.y - rightEar.y) * 10,
            z: Math.abs(leftEar.x - rightEar.x) * 10
          };

          hat.setAttribute('position', position);
          hat.setAttribute('scale', scale);
          labelElement.style.display = 'block';
        } else {
          labelElement.style.display = 'none';
        }
      } else {
        labelElement.style.display = 'none';
      }
    }
  </script>
</body>
</html>
